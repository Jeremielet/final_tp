"""
Pipeline principal d'entraÃ®nement du modÃ¨le de dÃ©tection de fraude.

Ce script exÃ©cute le pipeline complet :
1. Chargement des donnÃ©es
2. PrÃ©traitement
3. Feature engineering
4. EntraÃ®nement avec Optuna + MLflow
5. Sauvegarde du modÃ¨le

Usage:
    python run_pipeline.py
"""

import argparse
from pathlib import Path

# Imports des modules du projet
from src.data.load_data import load_raw_data, get_data_info
from src.preprocessing.preprocess import preprocess_data, validate_data
from src.features.build_features import build_features
from src.models.train import train_with_mlflow


def main(data_path: str = "data/raw/fraud_synth_10000.csv",
         n_trials: int = 30,
         experiment_name: str = "Fraud Detection"):
    """
    ExÃ©cute le pipeline complet d'entraÃ®nement.

    Args:
        data_path: Chemin vers les donnÃ©es brutes
        n_trials: Nombre d'essais pour Optuna
        experiment_name: Nom de l'expÃ©rience MLflow
    """
    print("="*80)
    print("ğŸš€ PIPELINE DE DÃ‰TECTION DE FRAUDE")
    print("="*80)
    print(f"Configuration :")
    print(f"  - Data: {data_path}")
    print(f"  - Optuna trials: {n_trials}")
    print(f"  - MLflow experiment: {experiment_name}")
    print("="*80 + "\n")

    # ========================================================================
    # Ã‰TAPE 1 : Chargement des donnÃ©es
    # ========================================================================
    print("ğŸ“‚ Ã‰TAPE 1/5 : Chargement des donnÃ©es")
    print("-" * 80)

    df = load_raw_data(data_path)
    info = get_data_info(df)

    print(f"\nğŸ“Š Informations du dataset :")
    print(f"  - Lignes : {info['n_rows']:,}")
    print(f"  - Colonnes : {info['n_columns']}")
    print(f"  - Fraudes : {info['fraud_count']} ({info['fraud_percentage']:.2f}%)")
    print(f"  - Valeurs manquantes : {info['n_missing']}")
    print()

    # ========================================================================
    # Ã‰TAPE 2 : PrÃ©traitement
    # ========================================================================
    print("ğŸ§¹ Ã‰TAPE 2/5 : PrÃ©traitement des donnÃ©es")
    print("-" * 80)

    df_clean = preprocess_data(df)
    is_valid = validate_data(df_clean)

    if not is_valid:
        print("âŒ DonnÃ©es invalides - ArrÃªt du pipeline")
        return
    print()

    # ========================================================================
    # Ã‰TAPE 3 : Feature Engineering
    # ========================================================================
    print("âš™ï¸ Ã‰TAPE 3/5 : Feature Engineering")
    print("-" * 80)

    X, y = build_features(df_clean)
    print()

    # ========================================================================
    # Ã‰TAPE 4 : EntraÃ®nement avec Optuna + MLflow + Optimisation avancÃ©e
    # ========================================================================
    print("ğŸ¤– Ã‰TAPE 4/5 : EntraÃ®nement du modÃ¨le avec optimisation avancÃ©e")
    print("-" * 80)

    model, best_threshold, metrics = train_with_mlflow(
        X, y,
        experiment_name=experiment_name,
        n_trials=n_trials
    )
    print()

    # ========================================================================
    # Ã‰TAPE 5 : RÃ©sumÃ© final
    # ========================================================================
    print("=" * 80)
    print("âœ… PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
    print("=" * 80)
    print(f"\nğŸ“Š RÃ©sultats finaux sur le Test Set :")
    print(f"  - Threshold : {best_threshold:.4f} (optimisÃ© pour maximiser le Recall)")
    print(f"  - Accuracy  : {metrics['accuracy']:.4f}")
    print(f"  - Precision : {metrics['precision']:.4f}")
    print(f"  - Recall    : {metrics['recall']:.4f} â­")
    print(f"  - F1-Score  : {metrics['f1_score']:.4f}")
    print(f"  - ROC-AUC   : {metrics['roc_auc']:.4f}")

    print(f"\nğŸ’¾ Fichiers sauvegardÃ©s :")
    print(f"  - ModÃ¨le : artifacts/models/random_forest_model.pkl")
    print(f"  - Threshold : artifacts/models/best_threshold.txt")

    print(f"\nğŸ”§ Optimisations appliquÃ©es :")
    print(f"  - Cross-Validation ({n_trials} trials Optuna)")
    print(f"  - HyperparamÃ¨tres optimisÃ©s avec StratifiedKFold")
    print(f"  - Threshold optimisÃ© sur le validation set")
    print(f"  - Ã‰valuation finale sur le test set")

    print(f"\nğŸ“ˆ MLflow :")
    print(f"  - Experiment : {experiment_name}")
    print(f"  - Lancer l'UI : mlflow ui")
    print(f"  - URL : http://localhost:5000")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    # Parser les arguments de ligne de commande
    parser = argparse.ArgumentParser(
        description="Pipeline de dÃ©tection de fraude avec Random Forest"
    )

    parser.add_argument(
        "--data",
        type=str,
        default="data/raw/fraud_synth_10000.csv",
        help="Chemin vers les donnÃ©es brutes (default: data/raw/fraud_synth_10000.csv)"
    )

    parser.add_argument(
        "--trials",
        type=int,
        default=30,
        help="Nombre d'essais Optuna (default: 30)"
    )

    parser.add_argument(
        "--experiment",
        type=str,
        default="Fraud Detection",
        help="Nom de l'expÃ©rience MLflow (default: 'Fraud Detection')"
    )

    args = parser.parse_args()

    # ExÃ©cuter le pipeline
    main(
        data_path=args.data,
        n_trials=args.trials,
        experiment_name=args.experiment
    )

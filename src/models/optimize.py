"""
Module d'optimisation avanc√©e avec Optuna.

Ce module contient :
1. Cross-validation pour valider les hyperparam√®tres
2. Optimisation du threshold pour maximiser le Recall
3. S√©lection des meilleurs param√®tres via Optuna
"""

import numpy as np
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, precision_recall_curve
import optuna


def optimize_hyperparameters_with_cv(X_train, y_train, n_trials=30, cv_folds=5):
    """
    Optimise les hyperparam√®tres de Random Forest avec Optuna et Cross-Validation.

    Args:
        X_train: Features d'entra√Ænement
        y_train: Cible d'entra√Ænement
        n_trials: Nombre d'essais Optuna (default: 30)
        cv_folds: Nombre de folds pour la cross-validation (default: 5)

    Returns:
        dict: Meilleurs param√®tres trouv√©s
    """
    print(f"\nüîç Optimisation avec Optuna ({n_trials} trials)")
    print(f"   Cross-validation : {cv_folds}-fold")
    print("-" * 80)

    def objective(trial):
        """
        Fonction objectif pour Optuna.
        Teste des hyperparam√®tres avec cross-validation.
        """
        # Sugg√©rer des hyperparam√®tres
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 300),
            'max_depth': trial.suggest_int('max_depth', 5, 20),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),
            'class_weight': 'balanced',  # Toujours balanced
            'random_state': 42,
            'n_jobs': -1
        }

        # Cr√©er le mod√®le
        model = RandomForestClassifier(**params)

        # Cross-validation stratifi√©e (garde la m√™me proportion de fraudes)
        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)

        # Calculer le F1-Score moyen sur tous les folds
        scores = cross_val_score(
            model, X_train, y_train,
            cv=cv,
            scoring='f1',
            n_jobs=-1
        )

        # Retourner la moyenne des F1-Scores
        mean_f1 = scores.mean()

        return mean_f1

    # Cr√©er l'√©tude Optuna
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

    # Afficher les r√©sultats
    print(f"\n‚úì Optimisation termin√©e")
    print(f"  Meilleur F1-Score (CV) : {study.best_value:.4f}")
    print(f"\n  Meilleurs param√®tres :")
    for key, value in study.best_params.items():
        print(f"    {key}: {value}")

    return study.best_params


def find_best_threshold(model, X_val, y_val, metric='recall', min_precision=0.5):
    """
    Trouve le meilleur threshold pour optimiser une m√©trique donn√©e.

    Pour la d√©tection de fraude, on veut maximiser le Recall
    (d√©tecter le maximum de fraudes) tout en gardant une Precision acceptable.

    Args:
        model: Mod√®le entra√Æn√©
        X_val: Features de validation
        y_val: Cible de validation
        metric: M√©trique √† optimiser ('recall', 'f1', 'precision')
        min_precision: Precision minimale √† respecter (default: 0.5)

    Returns:
        tuple: (best_threshold, metrics_dict)
    """
    print(f"\nüéØ Optimisation du Threshold")
    print(f"   M√©trique √† maximiser : {metric}")
    print(f"   Precision minimale : {min_precision:.2f}")
    print("-" * 80)

    # Obtenir les probabilit√©s de pr√©diction
    y_pred_proba = model.predict_proba(X_val)[:, 1]

    # Calculer precision, recall pour diff√©rents thresholds
    precisions, recalls, thresholds = precision_recall_curve(y_val, y_pred_proba)

    # Calculer F1-Score pour chaque threshold
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)

    # Trouver le meilleur threshold selon la m√©trique
    best_threshold = 0.5
    best_score = 0
    best_metrics = {}

    for i, threshold in enumerate(thresholds):
        # Appliquer le threshold
        y_pred = (y_pred_proba >= threshold).astype(int)

        # Calculer les m√©triques
        recall = recalls[i]
        precision = precisions[i]
        f1 = f1_scores[i]

        # V√©rifier la contrainte de precision minimale
        if precision < min_precision:
            continue

        # S√©lectionner selon la m√©trique demand√©e
        if metric == 'recall':
            score = recall
        elif metric == 'f1':
            score = f1
        elif metric == 'precision':
            score = precision
        else:
            score = f1

        # Mettre √† jour si meilleur
        if score > best_score:
            best_score = score
            best_threshold = threshold
            best_metrics = {
                'threshold': threshold,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            }

    print(f"\n‚úì Meilleur threshold trouv√© : {best_threshold:.4f}")
    print(f"  Precision : {best_metrics['precision']:.4f}")
    print(f"  Recall    : {best_metrics['recall']:.4f} ‚≠ê")
    print(f"  F1-Score  : {best_metrics['f1_score']:.4f}")

    return best_threshold, best_metrics


def train_with_best_params(X_train, y_train, best_params):
    """
    Entra√Æne un mod√®le avec les meilleurs param√®tres trouv√©s.

    Args:
        X_train: Features d'entra√Ænement
        y_train: Cible d'entra√Ænement
        best_params: Meilleurs param√®tres d'Optuna

    Returns:
        Mod√®le entra√Æn√©
    """
    print(f"\nü§ñ Entra√Ænement du mod√®le final")
    print("-" * 80)

    # Ajouter les param√®tres fixes
    final_params = best_params.copy()
    final_params['class_weight'] = 'balanced'
    final_params['random_state'] = 42
    final_params['n_jobs'] = -1

    # Cr√©er et entra√Æner le mod√®le
    model = RandomForestClassifier(**final_params)
    model.fit(X_train, y_train)

    print(f"‚úì Mod√®le entra√Æn√© avec les meilleurs param√®tres")

    return model


def evaluate_with_threshold(model, X_test, y_test, threshold=0.5):
    """
    √âvalue un mod√®le avec un threshold personnalis√©.

    Args:
        model: Mod√®le entra√Æn√©
        X_test: Features de test
        y_test: Cible de test
        threshold: Threshold de d√©cision (default: 0.5)

    Returns:
        dict: M√©triques d'√©valuation
    """
    # Pr√©dictions avec threshold personnalis√©
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_pred_proba >= threshold).astype(int)

    # Calculer les m√©triques
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score,
        f1_score, roc_auc_score, confusion_matrix
    )

    metrics = {
        'threshold': threshold,
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'f1_score': f1_score(y_test, y_pred),
        'roc_auc': roc_auc_score(y_test, y_pred_proba)
    }

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    metrics['true_negatives'] = int(tn)
    metrics['false_positives'] = int(fp)
    metrics['false_negatives'] = int(fn)
    metrics['true_positives'] = int(tp)

    return metrics


def optimize_and_train(X_train, y_train, X_val, y_val, n_trials=30, cv_folds=5):
    """
    Pipeline complet d'optimisation :
    1. Optimise les hyperparam√®tres avec Optuna + CV
    2. Entra√Æne le mod√®le avec les meilleurs param√®tres
    3. Optimise le threshold sur le validation set
    4. Retourne le mod√®le final et le threshold optimal

    Args:
        X_train: Features d'entra√Ænement
        y_train: Cible d'entra√Ænement
        X_val: Features de validation
        y_val: Cible de validation
        n_trials: Nombre d'essais Optuna
        cv_folds: Nombre de folds pour CV

    Returns:
        tuple: (model, best_threshold, best_params)
    """
    print("\n" + "="*80)
    print("OPTIMISATION COMPL√àTE")
    print("="*80)

    # 1. Optimiser les hyperparam√®tres avec CV
    best_params = optimize_hyperparameters_with_cv(
        X_train, y_train,
        n_trials=n_trials,
        cv_folds=cv_folds
    )

    # 2. Entra√Æner avec les meilleurs param√®tres
    model = train_with_best_params(X_train, y_train, best_params)

    # 3. Optimiser le threshold
    best_threshold, threshold_metrics = find_best_threshold(
        model, X_val, y_val,
        metric='recall',  # Maximiser le Recall pour la d√©tection de fraude
        min_precision=0.5  # Garder au moins 50% de precision
    )

    print("\n" + "="*80)
    print("‚úì OPTIMISATION TERMIN√âE")
    print("="*80)

    return model, best_threshold, best_params


if __name__ == "__main__":
    # Test du module
    from src.data.load_data import load_raw_data
    from src.preprocessing.preprocess import preprocess_data
    from src.features.build_features import build_features
    from sklearn.model_selection import train_test_split

    # Charger et pr√©parer les donn√©es
    df = load_raw_data()
    df_clean = preprocess_data(df)
    X, y = build_features(df_clean)

    # Split train/val/test
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )

    # Optimiser et entra√Æner
    model, threshold, params = optimize_and_train(
        X_train, y_train,
        X_val, y_val,
        n_trials=10,  # 10 trials pour le test
        cv_folds=3
    )

    # √âvaluer sur le test set
    metrics = evaluate_with_threshold(model, X_test, y_test, threshold)

    print(f"\nüìä R√©sultats sur le Test Set :")
    print(f"  Threshold : {metrics['threshold']:.4f}")
    print(f"  Recall    : {metrics['recall']:.4f} ‚≠ê")
    print(f"  Precision : {metrics['precision']:.4f}")
    print(f"  F1-Score  : {metrics['f1_score']:.4f}")

# Guide d'Utilisation du Pipeline

Ce guide explique comment utiliser le pipeline d'entraÃ®nement du modÃ¨le de dÃ©tection de fraude.

## ğŸ—ï¸ Architecture du Pipeline

Le pipeline est organisÃ© en modules Python clairs et simples :

```
final_tp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ load_data.py          # Chargement des donnÃ©es
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess.py         # Nettoyage des donnÃ©es
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py     # Feature engineering
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ train.py              # EntraÃ®nement + Optuna + MLflow
â”œâ”€â”€ run_pipeline.py               # Script principal
â””â”€â”€ configs/
    â””â”€â”€ config.yaml               # Configuration
```

## ğŸš€ Utilisation

### 1. ExÃ©cution simple

```bash
python run_pipeline.py
```

### 2. Avec options personnalisÃ©es

```bash
# Changer le nombre d'essais Optuna
python run_pipeline.py --trials 50

# Changer le nom de l'expÃ©rience MLflow
python run_pipeline.py --experiment "Mon Experience"

# Utiliser un autre fichier de donnÃ©es
python run_pipeline.py --data data/raw/autre_fichier.csv
```

### 3. Toutes les options

```bash
python run_pipeline.py \
  --data data/raw/fraud_synth_10000.csv \
  --trials 30 \
  --experiment "Fraud Detection"
```

## ğŸ“Š Ã‰tapes du Pipeline

### Ã‰tape 1 : Chargement des donnÃ©es
**Fichier** : `src/data/load_data.py`

- Charge le fichier CSV brut
- Affiche les informations du dataset
- VÃ©rifie que le fichier existe

```python
from src.data.load_data import load_raw_data

df = load_raw_data("data/raw/fraud_synth_10000.csv")
```

### Ã‰tape 2 : PrÃ©traitement
**Fichier** : `src/preprocessing/preprocess.py`

- VÃ©rifie les valeurs manquantes (aucune pour ce dataset)
- VÃ©rifie les doublons
- Valide que les donnÃ©es sont correctes

```python
from src.preprocessing.preprocess import preprocess_data

df_clean = preprocess_data(df)
```

### Ã‰tape 3 : Feature Engineering
**Fichier** : `src/features/build_features.py`

- SÃ©lectionne les 6 features importantes :
  - `is_foreign_transaction`
  - `account_age_days`
  - `country_risk`
  - `num_transactions_24h`
  - `transaction_amount`
  - `device_type`

- Encode les variables catÃ©gorielles :
  - `country_risk` â†’ One-Hot Encoding (3 colonnes)
  - `device_type` â†’ One-Hot Encoding (3 colonnes)

- SÃ©pare X (features) et y (cible)

```python
from src.features.build_features import build_features

X, y = build_features(df_clean)
```

### Ã‰tape 4 : EntraÃ®nement
**Fichier** : `src/models/train.py`

1. **Split Train/Test (80/20)**
   - StratifiÃ© pour garder la mÃªme proportion de fraudes

2. **Optimisation Optuna (30 trials)**
   - Optimise les hyperparamÃ¨tres de Random Forest
   - Maximise le F1-Score
   - Teste diffÃ©rentes combinaisons

3. **EntraÃ®nement du meilleur modÃ¨le**
   - Utilise les meilleurs paramÃ¨tres trouvÃ©s
   - `class_weight='balanced'` pour gÃ©rer le dÃ©sÃ©quilibre

4. **Ã‰valuation sur le test set**
   - Accuracy, Precision, Recall, F1, ROC-AUC
   - Matrice de confusion

5. **Tracking MLflow**
   - Enregistre tous les paramÃ¨tres
   - Enregistre toutes les mÃ©triques
   - Sauvegarde le modÃ¨le

6. **Sauvegarde**
   - ModÃ¨le : `artifacts/models/random_forest_model.pkl`

```python
from src.models.train import train_with_mlflow

model, metrics = train_with_mlflow(X, y, n_trials=30)
```

## ğŸ“ˆ Visualiser les rÃ©sultats avec MLflow

### Lancer l'interface MLflow

```bash
mlflow ui
```

Puis ouvrir : http://localhost:5000

### Ce que vous verrez

- **Experiments** : Toutes vos expÃ©riences
- **Runs** : Chaque exÃ©cution du pipeline
- **Parameters** : HyperparamÃ¨tres testÃ©s
- **Metrics** : Accuracy, Precision, Recall, F1, ROC-AUC
- **Artifacts** : ModÃ¨le sauvegardÃ©

## ğŸ¯ RÃ©sultats Attendus

AprÃ¨s l'exÃ©cution, vous obtiendrez :

### 1. ModÃ¨le entraÃ®nÃ©
```
artifacts/models/random_forest_model.pkl
```

### 2. MÃ©triques affichÃ©es
```
ğŸ“Š RÃ©sultats sur le Test Set :
  Accuracy  : 0.9XXX
  Precision : 0.XXX
  Recall    : 0.XXX â­
  F1-Score  : 0.XXX
  ROC-AUC   : 0.XXX

  Confusion Matrix :
    TN=XXXX | FP=XX
    FN=XX   | TP=XX
```

### 3. Tracking MLflow
- ExpÃ©rience crÃ©Ã©e dans `mlruns/`
- Tous les paramÃ¨tres et mÃ©triques enregistrÃ©s
- ModÃ¨le versionnÃ© et trackÃ©

## ğŸ”§ Tester les modules individuellement

### Tester le chargement
```bash
python -m src.data.load_data
```

### Tester le prÃ©traitement
```bash
python -m src.preprocessing.preprocess
```

### Tester le feature engineering
```bash
python -m src.features.build_features
```

### Tester l'entraÃ®nement
```bash
python -m src.models.train
```

## ğŸ’¡ Conseils

### Pour un test rapide
```bash
python run_pipeline.py --trials 10
```
- Seulement 10 essais Optuna
- ExÃ©cution en ~2-3 minutes

### Pour de meilleures performances
```bash
python run_pipeline.py --trials 100
```
- 100 essais Optuna
- ExÃ©cution en ~15-20 minutes
- Meilleurs hyperparamÃ¨tres

### Pour plusieurs expÃ©riences
```bash
python run_pipeline.py --experiment "Experiment 1" --trials 30
python run_pipeline.py --experiment "Experiment 2" --trials 50
python run_pipeline.py --experiment "Experiment 3" --trials 100
```
- Toutes les expÃ©riences sont trackÃ©es dans MLflow
- Facile de comparer les rÃ©sultats

## ğŸ“ Configuration

Modifiez `configs/config.yaml` pour changer :
- Les features sÃ©lectionnÃ©es
- Les plages de recherche Optuna
- Les paramÃ¨tres de split
- Les chemins de sauvegarde

## âœ… Avantages de cette architecture

1. **Modulaire** : Chaque Ã©tape est dans un fichier sÃ©parÃ©
2. **Testable** : Chaque module peut Ãªtre testÃ© individuellement
3. **RÃ©utilisable** : Les fonctions peuvent Ãªtre importÃ©es ailleurs
4. **Clair** : Code simple avec commentaires explicatifs
5. **TrackÃ©** : MLflow enregistre tout automatiquement
6. **Reproductible** : MÃªme random_state = mÃªmes rÃ©sultats

## ğŸ› Troubleshooting

### Erreur : "File not found"
â†’ VÃ©rifiez le chemin du fichier CSV

### Erreur : "Module not found"
â†’ ExÃ©cutez depuis la racine du projet

### MLflow UI ne dÃ©marre pas
â†’ VÃ©rifiez que le port 5000 est libre

### Optuna trop lent
â†’ RÃ©duisez `--trials` pour tester

## ğŸ“ Prochaines Ã©tapes

1. CrÃ©er une API FastAPI pour servir le modÃ¨le
2. Ajouter une interface Gradio
3. DÃ©ployer avec Docker
4. Ajouter des tests unitaires
5. CrÃ©er un CI/CD avec GitHub Actions
